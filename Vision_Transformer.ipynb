{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9990dd1-55e2-47ec-a00b-680ad469d385",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Processsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba5e981a-992c-48b9-9452-436372ea4780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = '/home/ec2-user/SageMaker/train/'\n",
    "test_dir = '/home/ec2-user/SageMaker/test/'\n",
    "files_dir = '/home/ec2-user/SageMaker/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea98b6f-e90f-41d7-b0e1-a2e2251c0fae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78da7f2d-39f0-4dd3-8c0b-b244a03dd239",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'Cassava Bacterial Blight (CBB)', '1': 'Cassava Brown Streak Disease (CBSD)', '2': 'Cassava Green Mottle (CGM)', '3': 'Cassava Mosaic Disease (CMD)', '4': 'Healthy'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(files_dir + '/label_num_to_disease_map.json', 'r') as f:\n",
    "    labels_info = json.load(f)\n",
    "\n",
    "NUM_LABELS = len(labels_info)\n",
    "print(labels_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02487866-ac62-4be0-af45-b40992c3b443",
   "metadata": {},
   "source": [
    "## Load Data with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb67fef6-1e4a-408c-9ad9-dcb6069a13f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2b1a54-6d54-4926-b5ec-d66fc65c8768",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"We're using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90fe6ee1-7575-47d9-bb8b-a0366ae5b3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(files_dir + '/train.csv')\n",
    "\n",
    "# Split the data into train, validation, and test sets with a ratio of 80:10:10\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aaaae3-d5b6-4afc-8291-0fcadc40a5dc",
   "metadata": {},
   "source": [
    "## regular images (non-transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b0a563-8a8f-4b3a-8e87-488765ddb558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, data, root_dir, transform=None):\n",
    "        self.image_labels = data\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.image_labels.iloc[index, 0])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.image_labels.iloc[index, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77600d7-bd04-4448-a357-7a1006609378",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869486d9-c095-405f-8e5c-e12b77631f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model so that we don't need to train the same model multiple times\n",
    "def save_model(model, model_name):\n",
    "  torch.save(model.state_dict(),  files_dir + 'saved_models/' + model_name + '.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad968d4f-3e5b-4ce0-9fcc-94d76c2f6f1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Vision Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04628d8a-9a76-4faf-b5cb-a61af8d9404d",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8922ebae-c946-4a0f-b4a0-a624d52d4b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LR = 2e-05\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ee3e9-30a1-424e-96b6-4c8c9a3b8711",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf80bf22-9a4d-4690-9233-1b87148ca4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For training -- includes two augmentations\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(p=0.3),\n",
    "        transforms.RandomVerticalFlip(p=0.3),\n",
    "        transforms.RandomResizedCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_valid = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e38107-2992-46da-8115-1c032b844d02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CassavaDataset(train_df, train_dir, transform=transforms_train)\n",
    "validation_dataset = CassavaDataset(val_df, train_dir, transform=transforms_valid)\n",
    "test_dataset = CassavaDataset(test_df, train_dir, transform=transforms_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f04cf03d-a794-4fba-9ad5-85a85501b360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf07dd-acf0-4a47-9885-9fa305284f7f",
   "metadata": {},
   "source": [
    "### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1432c156-ab1b-4cb8-8c19-9be4e3cf37ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: timm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.6.13)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (0.13.4)\n",
      "Requirement already satisfied: torch>=1.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (0.14.1)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torch>=1.7->timm) (4.4.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (4.63.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (2.28.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchvision->timm) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (1.26.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0857d1d7-e751-409e-b556-af582b7035f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "140f7187-57d0-460b-acf2-1e90c7b798e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n",
    "# model.head = torch.nn.Linear(model.head.in_features, NUM_LABELS)\n",
    "model.head = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model.head.in_features, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, NUM_LABELS)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5349c1d-98a6-4661-b564-be07af9acdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ff7d8-0c42-4aba-843c-0d4eaba3141d",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f65d2f5-140f-4b33-a308-f2b34ae51685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch:  0\n",
      "Current Batch:  50\n",
      "Current Batch:  100\n",
      "Current Batch:  150\n",
      "Current Batch:  200\n",
      "Current Batch:  250\n",
      "Current Batch:  300\n",
      "Current Batch:  350\n",
      "Current Batch:  400\n",
      "Current Batch:  450\n",
      "Current Batch:  500\n",
      "Current Batch:  550\n",
      "Current Batch:  600\n",
      "Current Batch:  650\n",
      "Current Batch:  700\n",
      "Current Batch:  750\n",
      "Current Batch:  800\n",
      "Current Batch:  850\n",
      "Current Batch:  900\n",
      "Current Batch:  950\n",
      "Current Batch:  1000\n",
      "Current Batch:  1050\n",
      "Train Accuracy: tensor(0.0390, device='cuda:0')\n",
      "Epoch 1:\n",
      "Training Loss: 1.074\n",
      "Validation Loss: 1.008\n",
      "Training Accuracy: 0.623\n",
      "Validation Accuracy: 0.647\n",
      "------------------------------\n",
      "Training Epoch:  1\n",
      "Current Batch:  50\n",
      "Current Batch:  100\n",
      "Current Batch:  150\n",
      "Current Batch:  200\n",
      "Current Batch:  250\n",
      "Current Batch:  300\n",
      "Current Batch:  350\n",
      "Current Batch:  400\n",
      "Current Batch:  450\n",
      "Current Batch:  500\n",
      "Current Batch:  550\n",
      "Current Batch:  600\n",
      "Current Batch:  650\n",
      "Current Batch:  700\n",
      "Current Batch:  750\n",
      "Current Batch:  800\n",
      "Current Batch:  850\n",
      "Current Batch:  900\n",
      "Current Batch:  950\n",
      "Current Batch:  1000\n",
      "Current Batch:  1050\n",
      "Train Accuracy: tensor(0.0410, device='cuda:0')\n",
      "Epoch 2:\n",
      "Training Loss: 0.944\n",
      "Validation Loss: 0.935\n",
      "Training Accuracy: 0.655\n",
      "Validation Accuracy: 0.656\n",
      "------------------------------\n",
      "Training Epoch:  2\n",
      "Current Batch:  50\n",
      "Current Batch:  100\n",
      "Current Batch:  150\n",
      "Current Batch:  200\n",
      "Current Batch:  250\n",
      "Current Batch:  300\n",
      "Current Batch:  350\n",
      "Current Batch:  400\n",
      "Current Batch:  450\n",
      "Current Batch:  500\n",
      "Current Batch:  550\n",
      "Current Batch:  600\n",
      "Current Batch:  650\n",
      "Current Batch:  700\n",
      "Current Batch:  750\n",
      "Current Batch:  800\n",
      "Current Batch:  850\n",
      "Current Batch:  900\n",
      "Current Batch:  950\n",
      "Current Batch:  1000\n",
      "Current Batch:  1050\n",
      "Train Accuracy: tensor(0.0418, device='cuda:0')\n",
      "Epoch 3:\n",
      "Training Loss: 0.889\n",
      "Validation Loss: 0.909\n",
      "Training Accuracy: 0.669\n",
      "Validation Accuracy: 0.671\n",
      "------------------------------\n",
      "Training Epoch:  3\n",
      "Current Batch:  50\n",
      "Current Batch:  100\n",
      "Current Batch:  150\n",
      "Current Batch:  200\n",
      "Current Batch:  250\n",
      "Current Batch:  300\n",
      "Current Batch:  350\n",
      "Current Batch:  400\n",
      "Current Batch:  450\n",
      "Current Batch:  500\n",
      "Current Batch:  550\n",
      "Current Batch:  600\n",
      "Current Batch:  650\n",
      "Current Batch:  700\n",
      "Current Batch:  750\n",
      "Current Batch:  800\n",
      "Current Batch:  850\n",
      "Current Batch:  900\n",
      "Current Batch:  950\n",
      "Current Batch:  1000\n",
      "Current Batch:  1050\n",
      "Train Accuracy: tensor(0.0425, device='cuda:0')\n",
      "Epoch 4:\n",
      "Training Loss: 0.862\n",
      "Validation Loss: 0.889\n",
      "Training Accuracy: 0.679\n",
      "Validation Accuracy: 0.677\n",
      "------------------------------\n",
      "Training Epoch:  4\n",
      "Current Batch:  50\n",
      "Current Batch:  100\n",
      "Current Batch:  150\n",
      "Current Batch:  200\n",
      "Current Batch:  250\n",
      "Current Batch:  300\n",
      "Current Batch:  350\n",
      "Current Batch:  400\n",
      "Current Batch:  450\n",
      "Current Batch:  500\n",
      "Current Batch:  550\n",
      "Current Batch:  600\n",
      "Current Batch:  650\n",
      "Current Batch:  700\n",
      "Current Batch:  750\n",
      "Current Batch:  800\n",
      "Current Batch:  850\n",
      "Current Batch:  900\n",
      "Current Batch:  950\n",
      "Current Batch:  1000\n",
      "Current Batch:  1050\n",
      "Train Accuracy: tensor(0.0431, device='cuda:0')\n",
      "Epoch 5:\n",
      "Training Loss: 0.834\n",
      "Validation Loss: 0.871\n",
      "Training Accuracy: 0.689\n",
      "Validation Accuracy: 0.681\n",
      "------------------------------\n",
      "Training Epoch:  5\n",
      "Current Batch:  50\n",
      "Current Batch:  100\n",
      "Current Batch:  150\n",
      "Current Batch:  200\n",
      "Current Batch:  250\n",
      "Current Batch:  300\n",
      "Current Batch:  350\n",
      "Current Batch:  400\n",
      "Current Batch:  450\n",
      "Current Batch:  500\n",
      "Current Batch:  550\n",
      "Current Batch:  600\n",
      "Current Batch:  650\n",
      "Current Batch:  700\n",
      "Current Batch:  750\n",
      "Current Batch:  800\n",
      "Current Batch:  850\n",
      "Current Batch:  900\n",
      "Current Batch:  950\n",
      "Current Batch:  1000\n",
      "Current Batch:  1050\n",
      "Train Accuracy: tensor(0.0433, device='cuda:0')\n",
      "Epoch 6:\n",
      "Training Loss: 0.825\n",
      "Validation Loss: 0.854\n",
      "Training Accuracy: 0.693\n",
      "Validation Accuracy: 0.689\n",
      "------------------------------\n",
      "Training Epoch:  6\n",
      "Current Batch:  50\n",
      "Current Batch:  100\n",
      "Current Batch:  150\n",
      "Current Batch:  200\n",
      "Current Batch:  250\n",
      "Current Batch:  300\n",
      "Current Batch:  350\n",
      "Current Batch:  400\n",
      "Current Batch:  450\n",
      "Current Batch:  500\n",
      "Current Batch:  550\n",
      "Current Batch:  600\n",
      "Current Batch:  650\n",
      "Current Batch:  700\n",
      "Current Batch:  750\n",
      "Current Batch:  800\n",
      "Current Batch:  850\n",
      "Current Batch:  900\n",
      "Current Batch:  950\n",
      "Current Batch:  1000\n",
      "Current Batch:  1050\n",
      "Train Accuracy: tensor(0.0438, device='cuda:0')\n",
      "Epoch 7:\n",
      "Training Loss: 0.803\n",
      "Validation Loss: 0.849\n",
      "Training Accuracy: 0.7\n",
      "Validation Accuracy: 0.688\n",
      "------------------------------\n",
      "Training Epoch:  7\n",
      "Current Batch:  50\n",
      "Current Batch:  100\n",
      "Current Batch:  150\n",
      "Current Batch:  200\n",
      "Current Batch:  250\n",
      "Current Batch:  300\n",
      "Current Batch:  350\n",
      "Current Batch:  400\n",
      "Current Batch:  450\n",
      "Current Batch:  500\n",
      "Current Batch:  550\n",
      "Current Batch:  600\n",
      "Current Batch:  650\n",
      "Current Batch:  700\n",
      "Current Batch:  750\n",
      "Current Batch:  800\n",
      "Current Batch:  850\n",
      "Current Batch:  900\n",
      "Current Batch:  950\n",
      "Current Batch:  1000\n",
      "Current Batch:  1050\n",
      "Train Accuracy: tensor(0.0441, device='cuda:0')\n",
      "Epoch 8:\n",
      "Training Loss: 0.788\n",
      "Validation Loss: 0.837\n",
      "Training Accuracy: 0.706\n",
      "Validation Accuracy: 0.696\n",
      "------------------------------\n",
      "Training Epoch:  8\n",
      "Current Batch:  50\n",
      "Current Batch:  100\n",
      "Current Batch:  150\n",
      "Current Batch:  200\n",
      "Current Batch:  250\n",
      "Current Batch:  300\n",
      "Current Batch:  350\n",
      "Current Batch:  400\n",
      "Current Batch:  450\n",
      "Current Batch:  500\n",
      "Current Batch:  550\n",
      "Current Batch:  600\n",
      "Current Batch:  650\n",
      "Current Batch:  700\n",
      "Current Batch:  750\n",
      "Current Batch:  800\n",
      "Current Batch:  850\n",
      "Current Batch:  900\n",
      "Current Batch:  950\n",
      "Current Batch:  1000\n",
      "Current Batch:  1050\n",
      "Train Accuracy: tensor(0.0446, device='cuda:0')\n",
      "Epoch 9:\n",
      "Training Loss: 0.774\n",
      "Validation Loss: 0.841\n",
      "Training Accuracy: 0.713\n",
      "Validation Accuracy: 0.687\n",
      "------------------------------\n",
      "Training Epoch:  9\n",
      "Current Batch:  50\n",
      "Current Batch:  100\n",
      "Current Batch:  150\n",
      "Current Batch:  200\n",
      "Current Batch:  250\n",
      "Current Batch:  300\n",
      "Current Batch:  350\n",
      "Current Batch:  400\n",
      "Current Batch:  450\n",
      "Current Batch:  500\n",
      "Current Batch:  550\n",
      "Current Batch:  600\n",
      "Current Batch:  650\n",
      "Current Batch:  700\n",
      "Current Batch:  750\n",
      "Current Batch:  800\n",
      "Current Batch:  850\n",
      "Current Batch:  900\n",
      "Current Batch:  950\n",
      "Current Batch:  1000\n",
      "Current Batch:  1050\n",
      "Train Accuracy: tensor(0.0445, device='cuda:0')\n",
      "Epoch 10:\n",
      "Training Loss: 0.771\n",
      "Validation Loss: 0.855\n",
      "Training Accuracy: 0.711\n",
      "Validation Accuracy: 0.703\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_loss, validation_loss = [], []\n",
    "train_acc, validation_acc = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Training Epoch: \", epoch)\n",
    "    batch_num = 0\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    correct, total = 0, 0 \n",
    "    total_acc= 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        batch_num += 1\n",
    "        if batch_num % 50 == 0:\n",
    "            print(\"Current Batch: \", batch_num)\n",
    "        # Forward pass\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "         \n",
    "        predictions = model(inputs)\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = (predictions.argmax(dim=1) == labels).float().mean()\n",
    "        total_acc += acc\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "            \n",
    "        _, predicted = torch.max(predictions, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss.append(running_loss / len(train_loader))\n",
    "    train_acc.append(correct/total)\n",
    "    print(\"Train Accuracy:\", total_acc / total)\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.\n",
    "    correct, total = 0, 0 \n",
    "    \n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(predictions, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    validation_loss.append(running_loss / len(val_loader))\n",
    "    validation_acc.append(correct/total)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "\n",
    "    print(f\"Training Loss:\", round(train_loss[epoch], 3))\n",
    "    print(f\"Validation Loss:\", round(validation_loss[epoch], 3))\n",
    "\n",
    "    print(f\"Training Accuracy:\", round(train_acc[epoch], 3))\n",
    "    print(f\"Validation Accuracy:\", round(validation_acc[epoch], 3))\n",
    "\n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d11cc865-8cfb-4629-81d5-032d01fe1ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model(model, \"vit_10_epochs_16_batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b08e11-41cc-432e-99ac-7f9769992ef9",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a718a0a3-6507-4625-a369-7081b4f4ceb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.7224299065420561\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_predictions = np.array([])\n",
    "true_labels = np.array([])\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    predictions = model(inputs)\n",
    "    \n",
    "    _, predicted = torch.max(predictions, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    true_labels = np.append(true_labels, labels.cpu().numpy())\n",
    "    test_predictions = np.concatenate((test_predictions, predicted.detach().cpu().numpy()))\n",
    "    \n",
    "print(\"Test Accuracy: \", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b562161e-1d25-48ff-84ba-fdf040ae2ade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.7224299065420561\n",
      "F1 Score:  0.6856029520564499\n",
      "Recall:  0.7224299065420561\n",
      "Precision:  0.6902457320080138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "f1 = f1_score(true_labels, test_predictions, average='weighted')\n",
    "recall = recall_score(true_labels, test_predictions, average='weighted')\n",
    "precision = precision_score(true_labels, test_predictions, average='weighted')\n",
    "accuracy = accuracy_score(true_labels, test_predictions)\n",
    "\n",
    "# Print the accuracy, F1 score, recall, and precision\n",
    "print(\"Test Accuracy: \", accuracy)\n",
    "print(\"F1 Score: \", f1)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Precision: \", precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
